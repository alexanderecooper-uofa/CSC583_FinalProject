{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f00e31d",
   "metadata": {},
   "source": [
    "## Set up the environment and prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5931ec",
   "metadata": {},
   "source": [
    "### Install the necessary python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f09cb08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/oberon/.local/lib/python3.11/site-packages (2.1.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/oberon/.local/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/oberon/.local/lib/python3.11/site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/oberon/.local/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/oberon/.local/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/oberon/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/oberon/.local/lib/python3.11/site-packages (1.25.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: whoosh in /home/oberon/.local/lib/python3.11/site-packages (2.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/oberon/.local/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: tqdm in /home/oberon/.local/lib/python3.11/site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: click in /home/oberon/.local/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/oberon/.local/lib/python3.11/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/oberon/.local/lib/python3.11/site-packages (from nltk) (2023.12.25)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install whoosh\n",
    "%pip install nltk\n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25de0bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/oberon/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e24d5aa",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d147d7a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T17:39:40.204587Z",
     "start_time": "2024-03-12T17:39:32.830101Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c16a835",
   "metadata": {},
   "source": [
    "### Parse the wiki files into a dataframe and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "075891c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T17:39:40.228588Z",
     "start_time": "2024-03-12T17:39:40.204587Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_wiki_file(content):\n",
    "    titles, text = [], []\n",
    "    start = -1\n",
    "    content = re.sub(r\"\\[\\[File:(.*)\\]\\]\", r\"---File:\\1---\", content) # wrap file links in triple brackets to avoid parsing\n",
    "    content = re.sub(r\"\\[\\[Image:(.*)\\]\\]\", r\"---Image:\\1---\", content) # wrap image links in triple brackets to avoid parsing\n",
    "    for match in re.finditer(\"^\\[\\[(.*)\\]\\]\\n\\n\", content, re.MULTILINE):\n",
    "        titles.append(match.group(1))\n",
    "        if start > -1:\n",
    "            t = re.sub(\"---File:(.*)---\", r\"[[File:\\1]]\", content[start:match.start()])\n",
    "            t = re.sub(\"---Image:(.*)---\", r\"[[Image:\\1]]\", t)\n",
    "            text.append(t)\n",
    "        start = match.end()\n",
    "    text.append(content[start:])\n",
    "    assert len(titles) == len(text)\n",
    "    return list(zip(titles, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c223279",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-12T17:45:32.219153Z",
     "start_time": "2024-03-12T17:43:07.671338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0014</td>\n",
       "      <td>Howard Hughes</td>\n",
       "      <td>CATEGORIES: Howard Hughes, 1905 births, 1976 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0014</td>\n",
       "      <td>Hook Of Holland</td>\n",
       "      <td>CATEGORIES: Rotterdam, Boroughs of Rotterdam, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0014</td>\n",
       "      <td>Hugh Binning</td>\n",
       "      <td>CATEGORIES: 1627 births, 1653 deaths, Scottish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0014</td>\n",
       "      <td>Henry Home, Lord Kames</td>\n",
       "      <td>CATEGORIES: 1696 births, 1782 deaths, 18th-cen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0014</td>\n",
       "      <td>Harwich</td>\n",
       "      <td>CATEGORIES: Harwich, Port cities and towns in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_id                   title  \\\n",
       "0    0014           Howard Hughes   \n",
       "1    0014         Hook Of Holland   \n",
       "2    0014            Hugh Binning   \n",
       "3    0014  Henry Home, Lord Kames   \n",
       "4    0014                 Harwich   \n",
       "\n",
       "                                                text  \n",
       "0  CATEGORIES: Howard Hughes, 1905 births, 1976 d...  \n",
       "1  CATEGORIES: Rotterdam, Boroughs of Rotterdam, ...  \n",
       "2  CATEGORIES: 1627 births, 1653 deaths, Scottish...  \n",
       "3  CATEGORIES: 1696 births, 1782 deaths, 18th-cen...  \n",
       "4  CATEGORIES: Harwich, Port cities and towns in ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_dir = \"./data/wiki\"\n",
    "data = {\"file_id\": [], \"title\": [], \"text\": []}\n",
    "redirects = {\"file_id\": [], \"title\": [], \"text\": [], \"redirect\": []}\n",
    "for fname in [f for f in os.listdir(wiki_dir) if not f.startswith(\"._\")]:\n",
    "    with open(os.path.join(wiki_dir, fname), \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    fid = fname.split(\"-\")[-1].replace(\".txt\", \"\")\n",
    "    for title, text in parse_wiki_file(content):\n",
    "        if text.startswith(\"#REDIRECT\"):\n",
    "            redirect = re.sub(\"\\[tpl\\].*\\[/tpl\\]\", \"\", text.replace(\"#REDIRECT\", \"\")).strip()\n",
    "            redirects[\"file_id\"].append(fid)\n",
    "            redirects[\"title\"].append(title.title())\n",
    "            redirects[\"text\"].append(text)\n",
    "            redirects[\"redirect\"].append(redirect)\n",
    "        else:\n",
    "            data[\"file_id\"].append(fid)\n",
    "            data[\"title\"].append(title.title())\n",
    "            data[\"text\"].append(text)\n",
    "wiki_df = pd.DataFrame(data).drop_duplicates(subset=\"title\")\n",
    "wiki_redirects_df = pd.DataFrame(redirects).drop_duplicates(subset=(\"title\", \"redirect\"))\n",
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd8f23ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>redirect</th>\n",
       "      <th>redirect_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0014</td>\n",
       "      <td>Hydroelectric Plant</td>\n",
       "      <td>#REDIRECT Hydroelectricity\\n\\n\\n</td>\n",
       "      <td>Hydroelectricity</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0014</td>\n",
       "      <td>Horse Breed</td>\n",
       "      <td>#REDIRECT List of horse breeds\\n\\n\\n</td>\n",
       "      <td>List of horse breeds</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0014</td>\n",
       "      <td>Horse Breeds</td>\n",
       "      <td>#REDIRECT list of horse breeds\\n\\n\\n</td>\n",
       "      <td>list of horse breeds</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0014</td>\n",
       "      <td>Melody Dominated Homophony</td>\n",
       "      <td>#REDIRECT Homophony\\n\\n\\n</td>\n",
       "      <td>Homophony</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0014</td>\n",
       "      <td>Historic List Of Cities Of Europe</td>\n",
       "      <td>#REDIRECT List of largest European cities in h...</td>\n",
       "      <td>List of largest European cities in history</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_id                              title  \\\n",
       "0    0014                Hydroelectric Plant   \n",
       "1    0014                        Horse Breed   \n",
       "2    0014                       Horse Breeds   \n",
       "3    0014         Melody Dominated Homophony   \n",
       "4    0014  Historic List Of Cities Of Europe   \n",
       "\n",
       "                                                text  \\\n",
       "0                   #REDIRECT Hydroelectricity\\n\\n\\n   \n",
       "1               #REDIRECT List of horse breeds\\n\\n\\n   \n",
       "2               #REDIRECT list of horse breeds\\n\\n\\n   \n",
       "3                          #REDIRECT Homophony\\n\\n\\n   \n",
       "4  #REDIRECT List of largest European cities in h...   \n",
       "\n",
       "                                     redirect  redirect_index  \n",
       "0                            Hydroelectricity              -1  \n",
       "1                        List of horse breeds              -1  \n",
       "2                        list of horse breeds              -1  \n",
       "3                                   Homophony              -1  \n",
       "4  List of largest European cities in history              -1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_lookups = {title: index for title, index in zip(wiki_df[\"title\"], wiki_df.index)}\n",
    "assert len(wiki_lookups) == len(wiki_df.index)\n",
    "\n",
    "# for each redirect, find the index of the redirected page for faster lookup\n",
    "def find_redirect_index(redirect):\n",
    "    if redirect not in wiki_lookups:\n",
    "        return -1 # TODO consider searching redirect on wikipedia to find real title\n",
    "    else:\n",
    "        return wiki_lookups[redirect]\n",
    "    \n",
    "redirect_indexes = [find_redirect_index(redirect) for redirect in wiki_redirects_df[\"redirect\"]]\n",
    "wiki_redirects_df[\"redirect_index\"] = redirect_indexes\n",
    "wiki_redirects_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35414787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151589, 126231)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df.to_pickle(\"./data/wiki.pkl\")\n",
    "wiki_redirects_df.to_pickle(\"./data/wiki_redirects.pkl\")\n",
    "\n",
    "len(wiki_df.index), len(wiki_redirects_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b121799",
   "metadata": {},
   "source": [
    "### Parse the [questions.txt](./data/questions.txt) file into a dataframe and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d91846c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEWSPAPERS</td>\n",
       "      <td>The dominant paper in our nation's capital, it...</td>\n",
       "      <td>The Washington Post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OLD YEAR'S RESOLUTIONS</td>\n",
       "      <td>The practice of pre-authorizing presidential u...</td>\n",
       "      <td>Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEWSPAPERS</td>\n",
       "      <td>Daniel Hertzberg &amp; James B. Stewart of this pa...</td>\n",
       "      <td>The Wall Street Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BROADWAY LYRICS</td>\n",
       "      <td>Song that says, \"you make me smile with my hea...</td>\n",
       "      <td>My Funny Valentine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POTPOURRI</td>\n",
       "      <td>In 2011 bell ringers for this charity started ...</td>\n",
       "      <td>The Salvation Army|Salvation Army</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 category                                           question  \\\n",
       "0              NEWSPAPERS  The dominant paper in our nation's capital, it...   \n",
       "1  OLD YEAR'S RESOLUTIONS  The practice of pre-authorizing presidential u...   \n",
       "2              NEWSPAPERS  Daniel Hertzberg & James B. Stewart of this pa...   \n",
       "3         BROADWAY LYRICS  Song that says, \"you make me smile with my hea...   \n",
       "4               POTPOURRI  In 2011 bell ringers for this charity started ...   \n",
       "\n",
       "                              answer  \n",
       "0                The Washington Post  \n",
       "1                             Taiwan  \n",
       "2            The Wall Street Journal  \n",
       "3                 My Funny Valentine  \n",
       "4  The Salvation Army|Salvation Army  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./data/questions.txt\", \"r\") as file:\n",
    "    questions = file.read().rstrip(\"\\n\").split(\"\\n\\n\")\n",
    "data = {\"category\": [], \"question\": [], \"answer\": []}\n",
    "for question in questions:\n",
    "    question = question.split(\"\\n\")\n",
    "    data[\"category\"].append(question[0])\n",
    "    data[\"question\"].append(question[1])\n",
    "    data[\"answer\"].append(question[2].title())\n",
    "questions_df = pd.DataFrame(data)\n",
    "questions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62aabc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df.to_pickle(\"./data/questions.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
